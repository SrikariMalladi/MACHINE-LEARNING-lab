## FEATURE ENGINEERING/PREPROCESSING



                                                                                            
### 1. Create a vector (array) of 1XN dimension representing N-dimensional feature vector of a sample. Write a program to compute the mean and variance of the elements present in the array.  Comment what the mean and variance of sample represents.
import numpy as np

def compute_mean_variance(vector):
    mean = np.mean(vector)
    variance = np.var(vector)
    return mean, variance

# Example vector creation
N = 5
sample_vector = np.array([2, 5, 7, 9, 11])

# Compute mean and variance
mean, variance = compute_mean_variance(sample_vector)

print("Sample Vector:", sample_vector)
print("Mean of Sample:", mean)
print("Variance of Sample:", variance)

# Comments on the mean and variance
print("\nComments:")
print("The mean of the sample represents the average value of the elements in the vector.")
print("The variance of the sample represents the measure of how much the values in the vector vary from the mean value. It indicates the dispersion or spread of the values in the vector.")
### 2. Create two vectors each of dimension 1XM each representing N-dimensional feature vector of a sample. Write a program to compute the Covariance between them. Comment what Covariance between two vectors represents.
import numpy as np

def compute_covariance(vector1, vector2):
    covariance = np.cov(vector1, vector2)[0][1]
    return covariance

# Example vectors creation
M = 5
sample_vector1 = np.array([1, 2, 3, 4, 5])
sample_vector2 = np.array([5, 4, 3, 2, 1])

# Compute covariance
covariance = compute_covariance(sample_vector1, sample_vector2)

print("Vector 1:", sample_vector1)
print("Vector 2:", sample_vector2)
print("Covariance between Vector 1 and Vector 2:", covariance)

# Comment on covariance
print("\nComments:")
print("Covariance between two vectors represents how much the variables in the vectors change together. If the covariance is positive, it indicates that the variables tend to increase or decrease together. If negative, one variable tends to increase when the other decreases. A covariance close to zero suggests that there is no linear relationship between the variables.")

### 3. Create two vectors each of dimension 1XN. Write a program to compute the Correlation between them. Comment what the Correlation represents.
import numpy as np

def compute_correlation(vector1, vector2):
    correlation = np.corrcoef(vector1, vector2)[0][1]
    return correlation

# Example vectors creation
N = 6
vector1 = np.array([1, 2, 3, 4, 5, 6])
vector2 = np.array([6, 5, 4, 3, 2, 1])

# Compute correlation
correlation = compute_correlation(vector1, vector2)

print("Vector 1:", vector1)
print("Vector 2:", vector2)
print("Correlation between Vector 1 and Vector 2:", correlation)

# Comment on correlation
print("\nComments:")
print("Correlation measures the strength and direction of the linear relationship between two variables. A correlation value close to 1 indicates a strong positive linear relationship, meaning when one variable increases, the other tends to increase as well. A value close to -1 indicates a strong negative linear relationship, implying that when one variable increases, the other tends to decrease. A correlation value close to 0 suggests no linear relationship between the variables.")

### 4. Create a Matrix of MXN dimension representing the M-dimensional feature vector for N number of samples i. e (i,j)th entry of the matrix represents the ith feature of jth sample. Write a program to compute the covariance matrix and correlation matrix. Comment on takeaways from these matrixes.
import numpy as np

def compute_covariance_matrix(matrix):
    covariance_matrix = np.cov(matrix)
    return covariance_matrix

def compute_correlation_matrix(matrix):
    correlation_matrix = np.corrcoef(matrix)
    return correlation_matrix

# Example matrix creation
M = 3  # Number of features
N = 4  # Number of samples
sample_matrix = np.array([[1, 2, 3, 4],
                          [5, 6, 7, 8],
                          [9, 10, 11, 12]])  

# Compute covariance matrix
covariance_matrix = compute_covariance_matrix(sample_matrix)

# Compute correlation matrix
correlation_matrix = compute_correlation_matrix(sample_matrix)

print("Sample Matrix:")
print(sample_matrix)
print("\nCovariance Matrix:")
print(covariance_matrix)
print("\nCorrelation Matrix:")
print(correlation_matrix)

# Comment on takeaways
print("\nComments:")
print("1. Covariance Matrix:")
print("- Diagonal elements represent the variance of each feature.")
print("- Off-diagonal elements represent the covariance between pairs of features.")
print("- Positive values indicate that the features increase or decrease together, while negative values indicate that they vary in opposite directions.")

print("\n2. Correlation Matrix:")
print("- Diagonal elements are always 1, as they represent the correlation of a feature with itself (perfect correlation).")
print("- Values close to 1 indicate strong positive linear relationships between features.")
print("- Values close to -1 indicate strong negative linear relationships between features.")
print("- Values close to 0 indicate weak or no linear relationship between features.")

